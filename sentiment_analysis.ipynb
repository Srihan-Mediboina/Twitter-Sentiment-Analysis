{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment-analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeOWYCIqJgyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BEKmvvJJk6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ca_df = pd.read_csv('ca_labeled.csv', index_col=[0])\n",
        "ny_df = pd.read_csv('ny_labeled.csv', index_col=[0])\n",
        "tx_df = pd.read_csv('tx_labeled.csv', index_col=[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9uIVxtbhKK5",
        "colab_type": "code",
        "outputId": "149f4a2c-387e-462b-bb6a-38932baf94ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ca_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>b'Only some businesses can open this wk. Yes t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>b'#California nurse just confirmed they are al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "      <td>b'I really wish phase 2 included hair and nail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>b'#California loosens rules for visitor in hos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>b'This is welcome news for #California. Policy...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   values                                         tweet_text\n",
              "0      -1  b'Only some businesses can open this wk. Yes t...\n",
              "1      -1  b'#California nurse just confirmed they are al...\n",
              "2      -1  b'I really wish phase 2 included hair and nail...\n",
              "3       0  b'#California loosens rules for visitor in hos...\n",
              "4       1  b'This is welcome news for #California. Policy..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bxN_-l3gnag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def features(value):\n",
        "  if(value == -1):\n",
        "    value = 'neg'\n",
        "    return value\n",
        "  elif(value == 1):\n",
        "    value = 'pos'\n",
        "    return value\n",
        "  else:\n",
        "    value = 'neu'\n",
        "    return value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtdDnsoshQCt",
        "colab_type": "code",
        "outputId": "9d25b174-ae67-4aa1-f832-2d4074c0d6c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ca_df['values'] = ca_df['values'].apply(features)\n",
        "ny_df['values'] = ny_df['values'].apply(features)\n",
        "tx_df['values'] = tx_df['values'].apply(features)\n",
        "\n",
        "ca_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>b'Only some businesses can open this wk. Yes t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>b'#California nurse just confirmed they are al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>b'I really wish phase 2 included hair and nail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neu</td>\n",
              "      <td>b'#California loosens rules for visitor in hos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>b'This is welcome news for #California. Policy...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  values                                         tweet_text\n",
              "0    neg  b'Only some businesses can open this wk. Yes t...\n",
              "1    neg  b'#California nurse just confirmed they are al...\n",
              "2    neg  b'I really wish phase 2 included hair and nail...\n",
              "3    neu  b'#California loosens rules for visitor in hos...\n",
              "4    pos  b'This is welcome news for #California. Policy..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g3Iczj0ieuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk \n",
        "\n",
        "from nltk import TweetTokenizer\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "def tokenize_tweets(tweet):\n",
        "  tweet = tweet_tokenizer.tokenize(tweet)\n",
        "  return tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "___H6a6ritMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ca_df['tweet_text'] = ca_df['tweet_text'].apply(tokenize_tweets)\n",
        "ny_df['tweet_text'] = ny_df['tweet_text'].apply(tokenize_tweets)\n",
        "tx_df['tweet_text'] = tx_df['tweet_text'].apply(tokenize_tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEY6eqAhM9Z0",
        "colab_type": "code",
        "outputId": "69f27e5e-9917-46b3-97aa-469be9c48607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ca_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'Only, some, businesses, can, open, this, wk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b, ', #California, nurse, just, confirmed, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'I, really, wish, phase, 2, included, hair, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neu</td>\n",
              "      <td>[b, ', #California, loosens, rules, for, visit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>[b'This, is, welcome, news, for, #California, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  values                                         tweet_text\n",
              "0    neg  [b'Only, some, businesses, can, open, this, wk...\n",
              "1    neg  [b, ', #California, nurse, just, confirmed, th...\n",
              "2    neg  [b'I, really, wish, phase, 2, included, hair, ...\n",
              "3    neu  [b, ', #California, loosens, rules, for, visit...\n",
              "4    pos  [b'This, is, welcome, news, for, #California, ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZZJ_yxCji5Y",
        "colab_type": "code",
        "outputId": "0557ccb1-184d-436b-8f45-57ef6080528a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(tweet):\n",
        "  tweet = [n for n in tweet if not n in stop_words]\n",
        "  return tweet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EYP9wWqkB2o",
        "colab_type": "code",
        "outputId": "d90a2539-b219-4992-eeae-42cb34af1881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ca_df['tweet_text'] = ca_df['tweet_text'].apply(remove_stopwords)\n",
        "ny_df['tweet_text'] = ny_df['tweet_text'].apply(remove_stopwords)\n",
        "tx_df['tweet_text'] = tx_df['tweet_text'].apply(remove_stopwords)\n",
        "\n",
        "ca_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'Only, businesses, open, wk, ., Yes, wanna, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b, ', #California, nurse, confirmed, saying, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'I, really, wish, phase, 2, included, hair, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neu</td>\n",
              "      <td>[b, ', #California, loosens, rules, visitor, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>[b'This, welcome, news, #California, ., Policy...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  values                                         tweet_text\n",
              "0    neg  [b'Only, businesses, open, wk, ., Yes, wanna, ...\n",
              "1    neg  [b, ', #California, nurse, confirmed, saying, ...\n",
              "2    neg  [b'I, really, wish, phase, 2, included, hair, ...\n",
              "3    neu  [b, ', #California, loosens, rules, visitor, h...\n",
              "4    pos  [b'This, welcome, news, #California, ., Policy..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO6vME7CKEZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def cleanTxt(text):\n",
        "    text = re.sub('@[A-Za-z0â€“9]+', '', text)\n",
        "    text = re.sub('#', '', text)\n",
        "    text = re.sub('RT[\\s]+', '', text)\n",
        "    text = re.sub('https?:\\/\\/\\S+', '', text)\n",
        "    text = re.sub('/', '', text)\n",
        "    text = text.replace('\\\\', '')\n",
        "    \n",
        "    text = re.sub('x97', '', text)\n",
        "    text = re.sub('xa3', '', text)\n",
        "    text = re.sub('x98People', '', text)\n",
        "    text = re.sub('x98', '', text)\n",
        "    text = re.sub('xa0', '', text)\n",
        "    text = re.sub('x94and', '', text)\n",
        "    text = re.sub('x96', '', text)\n",
        "    text = re.sub('x99s', '', text)\n",
        "    text = re.sub('x91', '', text)\n",
        "    text = re.sub('x8a', '', text)\n",
        "    text = re.sub('xba', '', text)\n",
        "    text = re.sub('x9b', '', text)\n",
        "    text = re.sub('xbc', '', text)\n",
        "    text = re.sub('x92', '', text)\n",
        "    text = re.sub('xbf', '', text)\n",
        "    text = re.sub('x89https', '', text)\n",
        "    text = re.sub('x94By', '', text)\n",
        "    text = re.sub('x8f', '', text)\n",
        "    text = re.sub('xb8', '', text)\n",
        "    text = re.sub('xa4', '', text)\n",
        "    text = re.sub('xa5', '', text)\n",
        "    text = re.sub('x87', '', text)\n",
        "    text = re.sub('xa5WOW', '', text)\n",
        "    text = re.sub('x94', '', text)\n",
        "    text = re.sub('x95', '', text)\n",
        "    text = re.sub('xb3', '', text)\n",
        "    text = re.sub('x89', '', text)\n",
        "    text = re.sub('x9f', '', text)\n",
        "    text = re.sub('x9ccoronavirus', '', text)\n",
        "    text = re.sub('xbd', '', text)\n",
        "    text = re.sub('x9cnatural', '', text)\n",
        "    text = re.sub('x9cmusic', '', text)\n",
        "    text = re.sub('xa9', '', text)\n",
        "    text = re.sub('x82', '', text)\n",
        "    text = re.sub('xc2', '', text)\n",
        "    text = re.sub('x83', '', text)\n",
        "    text = re.sub('x99all', '', text)\n",
        "    text = re.sub('xb1al', '', text)\n",
        "    text = re.sub('x9cessential', '', text)\n",
        "    text = re.sub('x9cEveryone', '', text)\n",
        "    text = re.sub('x8e', '', text)\n",
        "    text = re.sub('x98Reopen', '', text)\n",
        "    text = re.sub('xe3', '', text)\n",
        "    text = re.sub('xa2', '', text)\n",
        "    text = re.sub('x80', '', text)\n",
        "    text = re.sub('x99m', '', text)\n",
        "    text = re.sub('x90', '', text)\n",
        "    text = re.sub('x9e', '', text)\n",
        "    text = re.sub('x99', '', text)\n",
        "    text = re.sub('xb9', '', text)\n",
        "    text = re.sub('xbb', '', text)\n",
        "    text = re.sub('x99re', '', text)\n",
        "    text = re.sub('xa3https', '', text)\n",
        "    text = re.sub('x98Burden', '', text)\n",
        "    text = re.sub('x9cprogressives', '', text)\n",
        "    text = re.sub('xb1d19', '', text)\n",
        "    text = re.sub('xaa', '', text)\n",
        "    text = re.sub('x86', '', text)\n",
        "    text = re.sub('x8c', '', text)\n",
        "    text = re.sub('x93', '', text)\n",
        "    text = re.sub('x9d', '', text)\n",
        "    text = re.sub('x88', '', text)\n",
        "    text = re.sub('x99t', '', text)\n",
        "    text = re.sub('xef', '', text)\n",
        "    text = re.sub('xf0', '', text)\n",
        "    text = re.sub('xa7', '', text)\n",
        "    text = re.sub('xb7', '', text)\n",
        "    text = re.sub('x9cThe', '', text)\n",
        "    text = re.sub('x9c', '', text)\n",
        "    text = re.sub('x99mon', '', text)\n",
        "    text = re.sub('x99d', '', text)\n",
        "    text = re.sub('xb5', '', text)\n",
        "    text = re.sub('xc3', '', text)\n",
        "    text = re.sub('xe2', '', text)\n",
        "    text = re.sub('x8d', '', text)\n",
        "    text = re.sub('xb0', '', text)\n",
        "    text = re.sub('xa6it', '', text)\n",
        "    text = re.sub('x98CA', '', text)\n",
        "    text = re.sub('xc4', '', text)\n",
        "    text = re.sub('xa8', '', text)\n",
        "    text = re.sub('x9cthe', '', text)\n",
        "    text = re.sub('x99ve', '', text)\n",
        "    text = re.sub('x81', '', text)\n",
        "    text = re.sub('x8fTake', '', text)\n",
        "    text = re.sub('x85', '', text)\n",
        "    text = re.sub('x99S', '', text)\n",
        "    text = re.sub('xb8OPEN', '', text)\n",
        "    text = re.sub('xa6', '', text)\n",
        "    text = re.sub('x8fUplifting', '', text)\n",
        "    text = re.sub('xb8TYRANT', '', text)\n",
        "    text = re.sub('xac', '', text)\n",
        "    text = re.sub('x99ll', '', text)\n",
        "    text = re.sub('x9cfix', '', text)\n",
        "    text = re.sub('x98declared', '', text)\n",
        "    text = re.sub('xa1', '', text)\n",
        "    text = re.sub('x98fix', '', text)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg_KQzRAMHkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(ca_df['tweet_text'])):\n",
        "  for n in range(len(ca_df['tweet_text'][i])):\n",
        "    ca_df['tweet_text'][i][n] = cleanTxt(ca_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH4lVJ9POKfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(ny_df['tweet_text'])):\n",
        "  for n in range(len(ny_df['tweet_text'][i])):\n",
        "    ny_df['tweet_text'][i][n] = cleanTxt(ny_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UznA_j2cONbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(tx_df['tweet_text'])):\n",
        "  for n in range(len(tx_df['tweet_text'][i])):\n",
        "    tx_df['tweet_text'][i][n] = cleanTxt(tx_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEjvp9ZiNY0v",
        "colab_type": "code",
        "outputId": "419209fb-7bdb-4f02-dba5-8b808637d067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ca_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'Only, businesses, open, wk, ., Yes, wanna, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b, ', California, nurse, confirmed, saying, v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'I, really, wish, phase, 2, included, hair, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neu</td>\n",
              "      <td>[b, ', California, loosens, rules, visitor, ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>[b'This, welcome, news, California, ., Policy,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  values                                         tweet_text\n",
              "0    neg  [b'Only, businesses, open, wk, ., Yes, wanna, ...\n",
              "1    neg  [b, ', California, nurse, confirmed, saying, v...\n",
              "2    neg  [b'I, really, wish, phase, 2, included, hair, ...\n",
              "3    neu  [b, ', California, loosens, rules, visitor, ho...\n",
              "4    pos  [b'This, welcome, news, California, ., Policy,..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI-J0MYjMRqt",
        "colab_type": "code",
        "outputId": "377fda65-9b57-430f-bb45-b48e7eb3dd16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_tweets(tweet):\n",
        "  tweet = lemmatizer.lemmatize(tweet)\n",
        "  return tweet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK4VHWoCMfOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(ca_df['tweet_text'])):\n",
        "  for n in range(len(ca_df['tweet_text'][i])):\n",
        "    ca_df['tweet_text'][i][n] = lemmatize_tweets(ca_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(ny_df['tweet_text'])):\n",
        "  for n in range(len(ny_df['tweet_text'][i])):\n",
        "    ny_df['tweet_text'][i][n] = lemmatize_tweets(ny_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(tx_df['tweet_text'])):\n",
        "  for n in range(len(tx_df['tweet_text'][i])):\n",
        "    tx_df['tweet_text'][i][n] = lemmatize_tweets(tx_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pXWDXenKQKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "dataset = []\n",
        "\n",
        "ca_dataset = []\n",
        "for row in ca_df.itertuples(index = False):\n",
        "    ca_dataset.append((getattr(row, 'tweet_text'), getattr(row, 'values')))\n",
        "    \n",
        "ny_dataset = []\n",
        "for row in ny_df.itertuples(index = False):\n",
        "    ny_dataset.append((getattr(row, 'tweet_text'), getattr(row, 'values')))\n",
        "    \n",
        "tx_dataset = []\n",
        "for row in tx_df.itertuples(index = False):\n",
        "    tx_dataset.append((getattr(row, 'tweet_text'), getattr(row, 'values')))\n",
        "    \n",
        "dataset = ca_dataset + ny_dataset + tx_dataset\n",
        "\n",
        "\n",
        "random.shuffle(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vysq2FxNKR5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_words = []\n",
        "for i in range(len(ca_df.index)):\n",
        "    for w in ca_df.iat[i, 1]:\n",
        "        all_words.append(w.lower())\n",
        "        \n",
        "for i in range(len(ny_df.index)):\n",
        "    for w in ny_df.iat[i, 1]:\n",
        "        all_words.append(w.lower())\n",
        "        \n",
        "for i in range(len(tx_df.index)):\n",
        "    for w in tx_df.iat[i, 1]:\n",
        "        all_words.append(w.lower())\n",
        "\n",
        "\n",
        "all_words = nltk.FreqDist(all_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez7MNpdyKTw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_features = [item[0] for item in all_words.most_common(300)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvDg1d6FKVjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_features(tweet):\n",
        "    words = set(tweet)\n",
        "    features = {}\n",
        "    for w in word_features:\n",
        "        features[w] = (w in words)\n",
        "    \n",
        "    return features\n",
        "\n",
        "feature_sets = [(find_features(tweet), value) for (tweet, value) in dataset]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg8OVjU1KXCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set = feature_sets[:1200]\n",
        "testing_set = feature_sets[1200:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGlYBUMxKYST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = nltk.NaiveBayesClassifier.train(training_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYIABlFaKZze",
        "colab_type": "code",
        "outputId": "1f13b3f1-3456-452a-abc4-43ecfdebf876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(testing_set), len(training_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300 1200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RNsNt8TKbiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = []\n",
        "for i in range(len(testing_set)):\n",
        "    results.append(classifier.classify(testing_set[i][0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lXa85JTKc34",
        "colab_type": "code",
        "outputId": "8c2d3786-7815-499d-ff83-53f671c26601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(results))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igomLi-4KeTS",
        "colab_type": "code",
        "outputId": "ffe10a5b-2553-4d55-c043-8d11a233e90a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "error = 0\n",
        "for i in range(len(results)):\n",
        "    print(results[i], ' : ', testing_set[i][1])\n",
        "    if(results[i] != testing_set[i][1]):\n",
        "        error += 1\n",
        "\n",
        "error = (error/300) * 100\n",
        "        \n",
        "print(\"Error: \" + str(error) + \"%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neg\n",
            "pos  :  pos\n",
            "neg  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neg  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neg  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neg\n",
            "neu  :  neg\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neg  :  neg\n",
            "neg  :  neu\n",
            "pos  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  pos\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "pos  :  neg\n",
            "neu  :  pos\n",
            "neg  :  neg\n",
            "neg  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  pos\n",
            "neu  :  neu\n",
            "pos  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neg  :  neg\n",
            "neu  :  pos\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "neu  :  neg\n",
            "neg  :  neu\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neg  :  neg\n",
            "neg  :  neu\n",
            "pos  :  neg\n",
            "neg  :  neg\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  pos\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neg  :  neg\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  pos\n",
            "pos  :  neu\n",
            "pos  :  neu\n",
            "pos  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neg  :  pos\n",
            "neg  :  neu\n",
            "pos  :  pos\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neg  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "pos  :  pos\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  neu\n",
            "neg  :  pos\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  pos\n",
            "neu  :  neu\n",
            "pos  :  pos\n",
            "pos  :  neg\n",
            "neg  :  neg\n",
            "neg  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "neg  :  neg\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  pos\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "pos  :  pos\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  neu\n",
            "neg  :  neg\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "pos  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neg\n",
            "neu  :  pos\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neg  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  pos\n",
            "neg  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neg\n",
            "Error: 33.666666666666664%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxFy2fH_e201",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ca_new_df = pd.read_csv('COVID_California_current.csv')\n",
        "ny_new_df = pd.read_csv('COVID19_newyork_current.csv')\n",
        "tx_new_df = pd.read_csv('COVID19_texas_current.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcFRJqj5RJOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "ca_new_df['tweet_text'] = ca_new_df['tweet_text'].apply(tokenize_tweets)\n",
        "ny_new_df['tweet_text'] = ny_new_df['tweet_text'].apply(tokenize_tweets)\n",
        "tx_new_df['tweet_text'] = tx_new_df['tweet_text'].apply(tokenize_tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkAaNmZfRhhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ca_new_df['tweet_text'] = ca_new_df['tweet_text'].apply(remove_stopwords)\n",
        "ny_new_df['tweet_text'] = ny_new_df['tweet_text'].apply(remove_stopwords)\n",
        "tx_new_df['tweet_text'] = tx_new_df['tweet_text'].apply(remove_stopwords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgar4hEyRogy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "for i in range(len(ca_new_df['tweet_text'])):\n",
        "  for n in range(len(ca_new_df['tweet_text'][i])):\n",
        "    ca_new_df['tweet_text'][i][n] = cleanTxt(ca_new_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(ny_new_df['tweet_text'])):\n",
        "  for n in range(len(ny_new_df['tweet_text'][i])):\n",
        "    ny_new_df['tweet_text'][i][n] = cleanTxt(ny_new_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(tx_new_df['tweet_text'])):\n",
        "  for n in range(len(tx_new_df['tweet_text'][i])):\n",
        "    tx_new_df['tweet_text'][i][n] = cleanTxt(tx_new_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie44vvaISRmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "for i in range(len(ca_new_df['tweet_text'])):\n",
        "  for n in range(len(ca_new_df['tweet_text'][i])):\n",
        "    ca_new_df['tweet_text'][i][n] = lemmatize_tweets(ca_new_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(ny_new_df['tweet_text'])):\n",
        "  for n in range(len(ny_new_df['tweet_text'][i])):\n",
        "    ny_new_df['tweet_text'][i][n] = lemmatize_tweets(ny_new_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(tx_new_df['tweet_text'])):\n",
        "  for n in range(len(tx_new_df['tweet_text'][i])):\n",
        "    tx_new_df['tweet_text'][i][n] = lemmatize_tweets(tx_new_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdpvZetRTSxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "\n",
        "all_words_new = []\n",
        "for i in range(len(ca_new_df.index)):\n",
        "    for w in ca_new_df.iat[i, 1]:\n",
        "        all_words_new.append(w.lower())\n",
        "        \n",
        "for i in range(len(ny_new_df.index)):\n",
        "    for w in ny_new_df.iat[i, 1]:\n",
        "        all_words_new.append(w.lower())\n",
        "        \n",
        "for i in range(len(tx_new_df.index)):\n",
        "    for w in tx_new_df.iat[i, 1]:\n",
        "        all_words_new.append(w.lower())\n",
        "\n",
        "\n",
        "all_words_new = nltk.FreqDist(all_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpsXy6cSTk71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_features_new = [item[0] for item in all_words_new.most_common(300)]\n",
        "\n",
        "def find_features_new(tweet):\n",
        "    words = set(tweet)\n",
        "    features = {}\n",
        "    for w in word_features_new:\n",
        "        features[w] = (w in words)\n",
        "    \n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvjeYQ8UTw26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "results_new_ca = []\n",
        "\n",
        "for i in range(len(ca_new_df['tweet_text'])):\n",
        "  feature = find_features_new(ca_new_df['tweet_text'][i])\n",
        "  results_new_ca.append(classifier.classify(feature))\n",
        "\n",
        "results_new_ny = []\n",
        "\n",
        "for i in range(len(ny_new_df['tweet_text'])):\n",
        "  feature = find_features_new(ny_new_df['tweet_text'][i])\n",
        "  results_new_ny.append(classifier.classify(feature))\n",
        "\n",
        "results_new_tx = []\n",
        "\n",
        "for i in range(len(tx_new_df['tweet_text'])):\n",
        "  feature = find_features_new(tx_new_df['tweet_text'][i])\n",
        "  results_new_tx.append(classifier.classify(feature))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m47Jb-QlVv7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentiment_percent(results):\n",
        "  neg = 0\n",
        "  neu = 0\n",
        "  pos = 0\n",
        "  for i in results:\n",
        "    if(i == 'neg'):\n",
        "      neg += 1\n",
        "    elif(i == 'neu'):\n",
        "      neu += 1\n",
        "    else:\n",
        "      pos += 1\n",
        "\n",
        "  print(\"Pos:\", str(pos / len(results) * 100) + \"%\")\n",
        "  print(\"Neg:\", str(neg / len(results) * 100) + \"%\")\n",
        "  print(\"Neu:\", str(neu / len(results) * 100) + \"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FGZngPAWx9t",
        "colab_type": "code",
        "outputId": "a7a75945-188c-4391-e1bd-8581839f2804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "sentiment_percent(results_new_ca)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pos: 0.6160164271047228%\n",
            "Neg: 16.83778234086242%\n",
            "Neu: 82.54620123203286%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmUcB4U7W6JI",
        "colab_type": "code",
        "outputId": "10171ea9-680c-4fb5-c706-c8a55190534f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "sentiment_percent(results_new_ny)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pos: 1.636904761904762%\n",
            "Neg: 16.145833333333336%\n",
            "Neu: 82.21726190476191%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIWeaZJua-g1",
        "colab_type": "code",
        "outputId": "c617e171-5df9-466e-8fec-26642154896d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "sentiment_percent(results_new_tx)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pos: 2.079722703639515%\n",
            "Neg: 25.64991334488735%\n",
            "Neu: 72.27036395147314%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}