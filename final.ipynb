{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouzycQ6XeWvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import csv\n",
        "import tweepy\n",
        "import re\n",
        "\n",
        "def search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase):\n",
        "\n",
        "    #create authentication for accessing Twitter\n",
        "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "    auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "    #initialize Tweepy API\n",
        "    api = tweepy.API(auth)\n",
        "\n",
        "    #get the name of the spreadsheet we will write to\n",
        "    fname = '_'.join(re.findall(r\"#(\\w+)\", hashtag_phrase))\n",
        "\n",
        "    #open the spreadsheet we will write to\n",
        "    with open('%s.csv' % (fname), 'w') as file:\n",
        "\n",
        "        w = csv.writer(file)\n",
        "\n",
        "        #write header row to spreadsheet\n",
        "        w.writerow(['timestamp', 'tweet_text', 'username', 'all_hashtags', 'followers_count'])\n",
        "\n",
        "        #for each tweet matching our hashtags, write relevant info to the spreadsheet\n",
        "        for tweet in tweepy.Cursor(api.search, q=hashtag_phrase+' -filter:retweets', \\\n",
        "                                   lang=\"en\", tweet_mode='extended').items(5000):\n",
        "            w.writerow([tweet.created_at, tweet.full_text.replace('\\n',' ').encode('utf-8'), tweet.user.screen_name.encode('utf-8'), [e['text'] for e in tweet._json['entities']['hashtags']], tweet.user.followers_count])\n",
        "\n",
        "\n",
        "consumer_key = 'Snxk4IlXz80CEv5LGtcJ3I52n'\n",
        "consumer_secret = 'v3vDyMzwNrN9XWsAJro9tJqQTihvRscekmbFHHNUlbdxr5VDa0'\n",
        "access_token = '1185658874109583366-rcGy5ykUX3SjJMlF1YosHkS2udCrYJ'\n",
        "access_token_secret = 'wW0zikWScM4RUNprI2nCOIRsDN7lfNvqI7mugTWhqeBiz'\n",
        "\n",
        "hashtag_phrase = input('Hashtag Phrase ')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeOWYCIqJgyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BEKmvvJJk6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ca_df = pd.read_csv('ca_labeled.csv', index_col=[0])\n",
        "ny_df = pd.read_csv('ny_labeled.csv', index_col=[0])\n",
        "tx_df = pd.read_csv('tx_labeled.csv', index_col=[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bxN_-l3gnag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def features(value):\n",
        "  if(value == -1):\n",
        "    value = 'neg'\n",
        "    return value\n",
        "  elif(value == 1):\n",
        "    value = 'pos'\n",
        "    return value\n",
        "  else:\n",
        "    value = 'neu'\n",
        "    return value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9uIVxtbhKK5",
        "colab_type": "code",
        "outputId": "ae51327c-12c8-4e00-dba0-acea7b9be536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ca_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>b'Only some businesses can open this wk. Yes t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>b'#California nurse just confirmed they are al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "      <td>b'I really wish phase 2 included hair and nail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>b'#California loosens rules for visitor in hos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>b'This is welcome news for #California. Policy...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   values                                         tweet_text\n",
              "0      -1  b'Only some businesses can open this wk. Yes t...\n",
              "1      -1  b'#California nurse just confirmed they are al...\n",
              "2      -1  b'I really wish phase 2 included hair and nail...\n",
              "3       0  b'#California loosens rules for visitor in hos...\n",
              "4       1  b'This is welcome news for #California. Policy..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtdDnsoshQCt",
        "colab_type": "code",
        "outputId": "5d51f5bb-b6db-47ba-893e-38ba9eb8e1b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ca_df['values'] = ca_df['values'].apply(features)\n",
        "ny_df['values'] = ny_df['values'].apply(features)\n",
        "tx_df['values'] = tx_df['values'].apply(features)\n",
        "\n",
        "ca_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>b'Only some businesses can open this wk. Yes t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>b'#California nurse just confirmed they are al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>b'I really wish phase 2 included hair and nail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neu</td>\n",
              "      <td>b'#California loosens rules for visitor in hos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>b'This is welcome news for #California. Policy...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  values                                         tweet_text\n",
              "0    neg  b'Only some businesses can open this wk. Yes t...\n",
              "1    neg  b'#California nurse just confirmed they are al...\n",
              "2    neg  b'I really wish phase 2 included hair and nail...\n",
              "3    neu  b'#California loosens rules for visitor in hos...\n",
              "4    pos  b'This is welcome news for #California. Policy..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g3Iczj0ieuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import TweetTokenizer\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "def tokenize_tweets(tweet):\n",
        "  tweet = tweet_tokenizer.tokenize(tweet)\n",
        "  return tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "___H6a6ritMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ca_df['tweet_text'] = ca_df['tweet_text'].apply(tokenize_tweets)\n",
        "ny_df['tweet_text'] = ny_df['tweet_text'].apply(tokenize_tweets)\n",
        "tx_df['tweet_text'] = tx_df['tweet_text'].apply(tokenize_tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEY6eqAhM9Z0",
        "colab_type": "code",
        "outputId": "83420c5c-38dd-4526-98b2-75f7417027ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ca_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'Only, some, businesses, can, open, this, wk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b, ', #California, nurse, just, confirmed, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'I, really, wish, phase, 2, included, hair, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neu</td>\n",
              "      <td>[b, ', #California, loosens, rules, for, visit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>[b'This, is, welcome, news, for, #California, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  values                                         tweet_text\n",
              "0    neg  [b'Only, some, businesses, can, open, this, wk...\n",
              "1    neg  [b, ', #California, nurse, just, confirmed, th...\n",
              "2    neg  [b'I, really, wish, phase, 2, included, hair, ...\n",
              "3    neu  [b, ', #California, loosens, rules, for, visit...\n",
              "4    pos  [b'This, is, welcome, news, for, #California, ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZZJ_yxCji5Y",
        "colab_type": "code",
        "outputId": "ef0488f1-a259-4deb-ce94-921dd3494836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(tweet):\n",
        "  tweet = [n for n in tweet if not n in stop_words]\n",
        "  return tweet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EYP9wWqkB2o",
        "colab_type": "code",
        "outputId": "72f7b110-6e55-41a3-d524-8a252972b395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ca_df['tweet_text'] = ca_df['tweet_text'].apply(remove_stopwords)\n",
        "ny_df['tweet_text'] = ny_df['tweet_text'].apply(remove_stopwords)\n",
        "tx_df['tweet_text'] = tx_df['tweet_text'].apply(remove_stopwords)\n",
        "\n",
        "ca_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'Only, businesses, open, wk, ., Yes, wanna, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b, ', #California, nurse, confirmed, saying, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'I, really, wish, phase, 2, included, hair, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neu</td>\n",
              "      <td>[b, ', #California, loosens, rules, visitor, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>[b'This, welcome, news, #California, ., Policy...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  values                                         tweet_text\n",
              "0    neg  [b'Only, businesses, open, wk, ., Yes, wanna, ...\n",
              "1    neg  [b, ', #California, nurse, confirmed, saying, ...\n",
              "2    neg  [b'I, really, wish, phase, 2, included, hair, ...\n",
              "3    neu  [b, ', #California, loosens, rules, visitor, h...\n",
              "4    pos  [b'This, welcome, news, #California, ., Policy..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7oKA8dnNGEi",
        "colab_type": "code",
        "outputId": "740d2795-c5d0-4f27-f8b0-f9e8fb026a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ca_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'Only, businesses, open, wk, ., Yes, wanna, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b, ', #California, nurse, confirmed, saying, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'I, really, wish, phase, 2, included, hair, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neu</td>\n",
              "      <td>[b, ', #California, loosens, rules, visitor, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>[b'This, welcome, news, #California, ., Policy...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  values                                         tweet_text\n",
              "0    neg  [b'Only, businesses, open, wk, ., Yes, wanna, ...\n",
              "1    neg  [b, ', #California, nurse, confirmed, saying, ...\n",
              "2    neg  [b'I, really, wish, phase, 2, included, hair, ...\n",
              "3    neu  [b, ', #California, loosens, rules, visitor, h...\n",
              "4    pos  [b'This, welcome, news, #California, ., Policy..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO6vME7CKEZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def cleanTxt(text):\n",
        "    text = re.sub('@[A-Za-z0–9]+', '', text)\n",
        "    text = re.sub('#', '', text)\n",
        "    text = re.sub('RT[\\s]+', '', text)\n",
        "    text = re.sub('https?:\\/\\/\\S+', '', text)\n",
        "    text = re.sub('/', '', text)\n",
        "    text = text.replace('\\\\', '')\n",
        "    \n",
        "    text = re.sub('x97', '', text)\n",
        "    text = re.sub('xa3', '', text)\n",
        "    text = re.sub('x98People', '', text)\n",
        "    text = re.sub('x98', '', text)\n",
        "    text = re.sub('xa0', '', text)\n",
        "    text = re.sub('x94and', '', text)\n",
        "    text = re.sub('x96', '', text)\n",
        "    text = re.sub('x99s', '', text)\n",
        "    text = re.sub('x91', '', text)\n",
        "    text = re.sub('x8a', '', text)\n",
        "    text = re.sub('xba', '', text)\n",
        "    text = re.sub('x9b', '', text)\n",
        "    text = re.sub('xbc', '', text)\n",
        "    text = re.sub('x92', '', text)\n",
        "    text = re.sub('xbf', '', text)\n",
        "    text = re.sub('x89https', '', text)\n",
        "    text = re.sub('x94By', '', text)\n",
        "    text = re.sub('x8f', '', text)\n",
        "    text = re.sub('xb8', '', text)\n",
        "    text = re.sub('xa4', '', text)\n",
        "    text = re.sub('xa5', '', text)\n",
        "    text = re.sub('x87', '', text)\n",
        "    text = re.sub('xa5WOW', '', text)\n",
        "    text = re.sub('x94', '', text)\n",
        "    text = re.sub('x95', '', text)\n",
        "    text = re.sub('xb3', '', text)\n",
        "    text = re.sub('x89', '', text)\n",
        "    text = re.sub('x9f', '', text)\n",
        "    text = re.sub('x9ccoronavirus', '', text)\n",
        "    text = re.sub('xbd', '', text)\n",
        "    text = re.sub('x9cnatural', '', text)\n",
        "    text = re.sub('x9cmusic', '', text)\n",
        "    text = re.sub('xa9', '', text)\n",
        "    text = re.sub('x82', '', text)\n",
        "    text = re.sub('xc2', '', text)\n",
        "    text = re.sub('x83', '', text)\n",
        "    text = re.sub('x99all', '', text)\n",
        "    text = re.sub('xb1al', '', text)\n",
        "    text = re.sub('x9cessential', '', text)\n",
        "    text = re.sub('x9cEveryone', '', text)\n",
        "    text = re.sub('x8e', '', text)\n",
        "    text = re.sub('x98Reopen', '', text)\n",
        "    text = re.sub('xe3', '', text)\n",
        "    text = re.sub('xa2', '', text)\n",
        "    text = re.sub('x80', '', text)\n",
        "    text = re.sub('x99m', '', text)\n",
        "    text = re.sub('x90', '', text)\n",
        "    text = re.sub('x9e', '', text)\n",
        "    text = re.sub('x99', '', text)\n",
        "    text = re.sub('xb9', '', text)\n",
        "    text = re.sub('xbb', '', text)\n",
        "    text = re.sub('x99re', '', text)\n",
        "    text = re.sub('xa3https', '', text)\n",
        "    text = re.sub('x98Burden', '', text)\n",
        "    text = re.sub('x9cprogressives', '', text)\n",
        "    text = re.sub('xb1d19', '', text)\n",
        "    text = re.sub('xaa', '', text)\n",
        "    text = re.sub('x86', '', text)\n",
        "    text = re.sub('x8c', '', text)\n",
        "    text = re.sub('x93', '', text)\n",
        "    text = re.sub('x9d', '', text)\n",
        "    text = re.sub('x88', '', text)\n",
        "    text = re.sub('x99t', '', text)\n",
        "    text = re.sub('xef', '', text)\n",
        "    text = re.sub('xf0', '', text)\n",
        "    text = re.sub('xa7', '', text)\n",
        "    text = re.sub('xb7', '', text)\n",
        "    text = re.sub('x9cThe', '', text)\n",
        "    text = re.sub('x9c', '', text)\n",
        "    text = re.sub('x99mon', '', text)\n",
        "    text = re.sub('x99d', '', text)\n",
        "    text = re.sub('xb5', '', text)\n",
        "    text = re.sub('xc3', '', text)\n",
        "    text = re.sub('xe2', '', text)\n",
        "    text = re.sub('x8d', '', text)\n",
        "    text = re.sub('xb0', '', text)\n",
        "    text = re.sub('xa6it', '', text)\n",
        "    text = re.sub('x98CA', '', text)\n",
        "    text = re.sub('xc4', '', text)\n",
        "    text = re.sub('xa8', '', text)\n",
        "    text = re.sub('x9cthe', '', text)\n",
        "    text = re.sub('x99ve', '', text)\n",
        "    text = re.sub('x81', '', text)\n",
        "    text = re.sub('x8fTake', '', text)\n",
        "    text = re.sub('x85', '', text)\n",
        "    text = re.sub('x99S', '', text)\n",
        "    text = re.sub('xb8OPEN', '', text)\n",
        "    text = re.sub('xa6', '', text)\n",
        "    text = re.sub('x8fUplifting', '', text)\n",
        "    text = re.sub('xb8TYRANT', '', text)\n",
        "    text = re.sub('xac', '', text)\n",
        "    text = re.sub('x99ll', '', text)\n",
        "    text = re.sub('x9cfix', '', text)\n",
        "    text = re.sub('x98declared', '', text)\n",
        "    text = re.sub('xa1', '', text)\n",
        "    text = re.sub('x98fix', '', text)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIQXWlvbNIvt",
        "colab_type": "code",
        "outputId": "89b36d1a-65e6-4035-cfb4-948e50bb65cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ca_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'Only, businesses, open, wk, ., Yes, wanna, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b, ', #California, nurse, confirmed, saying, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>[b'I, really, wish, phase, 2, included, hair, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neu</td>\n",
              "      <td>[b, ', #California, loosens, rules, visitor, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>[b'This, welcome, news, #California, ., Policy...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  values                                         tweet_text\n",
              "0    neg  [b'Only, businesses, open, wk, ., Yes, wanna, ...\n",
              "1    neg  [b, ', #California, nurse, confirmed, saying, ...\n",
              "2    neg  [b'I, really, wish, phase, 2, included, hair, ...\n",
              "3    neu  [b, ', #California, loosens, rules, visitor, h...\n",
              "4    pos  [b'This, welcome, news, #California, ., Policy..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg_KQzRAMHkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(ca_df['tweet_text'])):\n",
        "  for n in range(len(ca_df['tweet_text'][i])):\n",
        "    ca_df['tweet_text'][i][n] = cleanTxt(ca_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH4lVJ9POKfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(ny_df['tweet_text'])):\n",
        "  for n in range(len(ny_df['tweet_text'][i])):\n",
        "    ny_df['tweet_text'][i][n] = cleanTxt(ny_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UznA_j2cONbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(tx_df['tweet_text'])):\n",
        "  for n in range(len(tx_df['tweet_text'][i])):\n",
        "    tx_df['tweet_text'][i][n] = cleanTxt(tx_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEjvp9ZiNY0v",
        "colab_type": "code",
        "outputId": "6689aeef-a7a4-41aa-caff-1ef5af6908aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ca_df.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>pos</td>\n",
              "      <td>[b'Thank, , funding, $, 1M, COVID19, relief, g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>neu</td>\n",
              "      <td>[b, \", California, rework, coronavirus, ethics...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>neu</td>\n",
              "      <td>[b'Is, California, workplace, complying, Cal, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>neu</td>\n",
              "      <td>[b'California, around, 4,500, additional, deat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>neu</td>\n",
              "      <td>[b'California, Governor, temporarily, closes, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    values                                         tweet_text\n",
              "495    pos  [b'Thank, , funding, $, 1M, COVID19, relief, g...\n",
              "496    neu  [b, \", California, rework, coronavirus, ethics...\n",
              "497    neu  [b'Is, California, workplace, complying, Cal, ...\n",
              "498    neu  [b'California, around, 4,500, additional, deat...\n",
              "499    neu  [b'California, Governor, temporarily, closes, ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI-J0MYjMRqt",
        "colab_type": "code",
        "outputId": "17356068-46d7-4893-c6dd-ee7f0ea1536d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_tweets(tweet):\n",
        "  tweet = lemmatizer.lemmatize(tweet)\n",
        "  return tweet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK4VHWoCMfOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(ca_df['tweet_text'])):\n",
        "  for n in range(len(ca_df['tweet_text'][i])):\n",
        "    ca_df['tweet_text'][i][n] = lemmatize_tweets(ca_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(ny_df['tweet_text'])):\n",
        "  for n in range(len(ny_df['tweet_text'][i])):\n",
        "    ny_df['tweet_text'][i][n] = lemmatize_tweets(ny_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(tx_df['tweet_text'])):\n",
        "  for n in range(len(tx_df['tweet_text'][i])):\n",
        "    tx_df['tweet_text'][i][n] = lemmatize_tweets(tx_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pXWDXenKQKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "#iterate through df and creates tuple for every tweet and every label, append tuples to respective dataset, create a master dataset \n",
        "dataset = []\n",
        "\n",
        "ca_dataset = []\n",
        "for row in ca_df.itertuples(index = False):\n",
        "    ca_dataset.append((getattr(row, 'tweet_text'), getattr(row, 'values')))\n",
        "    \n",
        "ny_dataset = []\n",
        "for row in ny_df.itertuples(index = False):\n",
        "    ny_dataset.append((getattr(row, 'tweet_text'), getattr(row, 'values')))\n",
        "    \n",
        "tx_dataset = []\n",
        "for row in tx_df.itertuples(index = False):\n",
        "    tx_dataset.append((getattr(row, 'tweet_text'), getattr(row, 'values')))\n",
        "    \n",
        "dataset = ca_dataset + ny_dataset + tx_dataset\n",
        "\n",
        "\n",
        "random.shuffle(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vysq2FxNKR5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "\n",
        "all_words = []\n",
        "for i in range(len(ca_df.index)):\n",
        "    for w in ca_df.iat[i, 1]:\n",
        "        all_words.append(w.lower())\n",
        "        \n",
        "for i in range(len(ny_df.index)):\n",
        "    for w in ny_df.iat[i, 1]:\n",
        "        all_words.append(w.lower())\n",
        "        \n",
        "for i in range(len(tx_df.index)):\n",
        "    for w in tx_df.iat[i, 1]:\n",
        "        all_words.append(w.lower())\n",
        "\n",
        "\n",
        "all_words = nltk.FreqDist(all_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez7MNpdyKTw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_features = [item[0] for item in all_words.most_common(300)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvDg1d6FKVjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_features(review):\n",
        "    words = set(review)\n",
        "    features = {}\n",
        "    for w in word_features:\n",
        "        features[w] = (w in words)\n",
        "    \n",
        "    return features\n",
        "\n",
        "feature_sets = [(find_features(review), rating) for (review, rating) in dataset]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg8OVjU1KXCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set = feature_sets[:1200]\n",
        "testing_set = feature_sets[1200:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGlYBUMxKYST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = nltk.NaiveBayesClassifier.train(training_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYIABlFaKZze",
        "colab_type": "code",
        "outputId": "22ad75ad-9716-4e11-9c3a-e2968b11327d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(testing_set), len(training_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300 1200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RNsNt8TKbiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = []\n",
        "for i in range(len(testing_set)):\n",
        "    results.append(classifier.classify(testing_set[i][0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lXa85JTKc34",
        "colab_type": "code",
        "outputId": "e19828f3-5803-4bc9-fd6a-9ca184ac179d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(results))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igomLi-4KeTS",
        "colab_type": "code",
        "outputId": "a4b67053-870e-41e2-96f6-af7e0f763ec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "error = 0\n",
        "for i in range(len(results)):\n",
        "    print(results[i], ' : ', testing_set[i][1])\n",
        "    if(results[i] != testing_set[i][1]):\n",
        "        error += 1\n",
        "\n",
        "error = (error/300) * 100\n",
        "        \n",
        "print(\"Error: \" + str(error) + \"%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "pos  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "pos  :  pos\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  pos\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "pos  :  pos\n",
            "neu  :  neu\n",
            "pos  :  pos\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neg  :  neg\n",
            "pos  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "pos  :  neu\n",
            "neg  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  pos\n",
            "neg  :  neg\n",
            "pos  :  neu\n",
            "neg  :  pos\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "pos  :  neg\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "pos  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neg  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  neg\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "pos  :  pos\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "pos  :  neu\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neg  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neg  :  neg\n",
            "pos  :  neu\n",
            "neg  :  neg\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neg  :  neg\n",
            "pos  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neg\n",
            "neg  :  neg\n",
            "neg  :  neu\n",
            "pos  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  neg\n",
            "neu  :  neu\n",
            "pos  :  neu\n",
            "neu  :  pos\n",
            "neg  :  neg\n",
            "neu  :  pos\n",
            "neu  :  neg\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neg  :  neg\n",
            "neu  :  pos\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neg  :  neg\n",
            "neg  :  pos\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "pos  :  neg\n",
            "neu  :  neu\n",
            "pos  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "pos  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neg  :  neu\n",
            "neg  :  pos\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "neu  :  pos\n",
            "neu  :  neg\n",
            "pos  :  pos\n",
            "neu  :  neu\n",
            "pos  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  pos\n",
            "neg  :  neg\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  neg\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neg\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "pos  :  pos\n",
            "pos  :  pos\n",
            "neg  :  neg\n",
            "neu  :  neg\n",
            "neg  :  neg\n",
            "pos  :  pos\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neg  :  neg\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neg\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "pos  :  pos\n",
            "neu  :  pos\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neg  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "pos  :  neu\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neg\n",
            "neu  :  neu\n",
            "neu  :  neu\n",
            "neg  :  neg\n",
            "Error: 37.333333333333336%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxFy2fH_e201",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "ca_new_df = pd.read_csv('COVID_California_current.csv')\n",
        "ny_new_df = pd.read_csv('COVID19_newyork_current.csv')\n",
        "tx_new_df = pd.read_csv('COVID19_texas_current.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcFRJqj5RJOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "ca_new_df['tweet_text'] = ca_new_df['tweet_text'].apply(tokenize_tweets)\n",
        "ny_new_df['tweet_text'] = ny_new_df['tweet_text'].apply(tokenize_tweets)\n",
        "tx_new_df['tweet_text'] = tx_new_df['tweet_text'].apply(tokenize_tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkAaNmZfRhhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ca_new_df['tweet_text'] = ca_new_df['tweet_text'].apply(remove_stopwords)\n",
        "ny_new_df['tweet_text'] = ny_new_df['tweet_text'].apply(remove_stopwords)\n",
        "tx_new_df['tweet_text'] = tx_new_df['tweet_text'].apply(remove_stopwords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgar4hEyRogy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "for i in range(len(ca_new_df['tweet_text'])):\n",
        "  for n in range(len(ca_new_df['tweet_text'][i])):\n",
        "    ca_new_df['tweet_text'][i][n] = cleanTxt(ca_new_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(ny_new_df['tweet_text'])):\n",
        "  for n in range(len(ny_new_df['tweet_text'][i])):\n",
        "    ny_new_df['tweet_text'][i][n] = cleanTxt(ny_new_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(tx_new_df['tweet_text'])):\n",
        "  for n in range(len(tx_new_df['tweet_text'][i])):\n",
        "    tx_new_df['tweet_text'][i][n] = cleanTxt(tx_new_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie44vvaISRmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "for i in range(len(ca_new_df['tweet_text'])):\n",
        "  for n in range(len(ca_new_df['tweet_text'][i])):\n",
        "    ca_new_df['tweet_text'][i][n] = lemmatize_tweets(ca_new_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(ny_new_df['tweet_text'])):\n",
        "  for n in range(len(ny_new_df['tweet_text'][i])):\n",
        "    ny_new_df['tweet_text'][i][n] = lemmatize_tweets(ny_new_df['tweet_text'][i][n])\n",
        "\n",
        "for i in range(len(tx_new_df['tweet_text'])):\n",
        "  for n in range(len(tx_new_df['tweet_text'][i])):\n",
        "    tx_new_df['tweet_text'][i][n] = lemmatize_tweets(tx_new_df['tweet_text'][i][n])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdpvZetRTSxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "\n",
        "all_words_new = []\n",
        "for i in range(len(ca_new_df.index)):\n",
        "    for w in ca_new_df.iat[i, 1]:\n",
        "        all_words_new.append(w.lower())\n",
        "        \n",
        "for i in range(len(ny_new_df.index)):\n",
        "    for w in ny_new_df.iat[i, 1]:\n",
        "        all_words_new.append(w.lower())\n",
        "        \n",
        "for i in range(len(tx_new_df.index)):\n",
        "    for w in tx_new_df.iat[i, 1]:\n",
        "        all_words_new.append(w.lower())\n",
        "\n",
        "\n",
        "all_words_new = nltk.FreqDist(all_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpsXy6cSTk71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "word_features_new = [item[0] for item in all_words_new.most_common(300)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvjeYQ8UTw26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "results_new_ca = []\n",
        "\n",
        "for i in range(len(ca_new_df['tweet_text'])):\n",
        "  feature = find_features(ca_new_df['tweet_text'][i])\n",
        "  results_new_ca.append(classifier.classify(feature))\n",
        "\n",
        "results_new_ny = []\n",
        "\n",
        "for i in range(len(ny_new_df['tweet_text'])):\n",
        "  feature = find_features(ny_new_df['tweet_text'][i])\n",
        "  results_new_ny.append(classifier.classify(feature))\n",
        "\n",
        "results_new_tx = []\n",
        "\n",
        "for i in range(len(tx_new_df['tweet_text'])):\n",
        "  feature = find_features(tx_new_df['tweet_text'][i])\n",
        "  results_new_tx.append(classifier.classify(feature))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m47Jb-QlVv7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentiment_percent(results):\n",
        "  neg = 0\n",
        "  neu = 0\n",
        "  pos = 0\n",
        "  for i in results:\n",
        "    if(i == 'neg'):\n",
        "      neg += 1\n",
        "    elif(i == 'neu'):\n",
        "      neu += 1\n",
        "    else:\n",
        "      pos += 1\n",
        "\n",
        "  print(\"Pos:\", str(pos / len(results) * 100) + \"%\")\n",
        "  print(\"Neg:\", str(neg / len(results) * 100) + \"%\")\n",
        "  print(\"Neu:\", str(neu / len(results) * 100) + \"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FGZngPAWx9t",
        "colab_type": "code",
        "outputId": "44529c05-168e-4fdc-d096-7f3b58403c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "sentiment_percent(results_new_ca)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pos: 5.544147843942506%\n",
            "Neg: 21.149897330595483%\n",
            "Neu: 73.30595482546201%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmUcB4U7W6JI",
        "colab_type": "code",
        "outputId": "f92eea2f-49f0-478a-bdcc-079f0711cd6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "sentiment_percent(results_new_ny)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pos: 7.8125%\n",
            "Neg: 17.038690476190478%\n",
            "Neu: 75.14880952380952%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIWeaZJua-g1",
        "colab_type": "code",
        "outputId": "48c72de9-d1ad-4af1-e787-d60e6f4434b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "sentiment_percent(results_new_tx)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pos: 7.452339688041594%\n",
            "Neg: 29.116117850953206%\n",
            "Neu: 63.43154246100519%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leVW-i-mb3fm",
        "colab_type": "text"
      },
      "source": [
        "https://www.youtube.com/watch?v=ujId4ipkBio\n",
        "\n",
        "https://gist.github.com/vickyqian/f70e9ab3910c7c290d9d715491cde44c\n",
        "\n",
        "https://towardsdatascience.com/twitter-sentiment-analysis-classification-using-nltk-python-fa912578614c\n",
        "\n",
        "https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f\n",
        "\n",
        "https://medium.com/@mr.adam.maj/machines-key-to-understanding-humans-how-i-used-natural-language-processing-to-analyze-human-9745d04e534b"
      ]
    }
  ]
}